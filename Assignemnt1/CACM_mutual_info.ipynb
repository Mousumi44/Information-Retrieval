{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preliminary', 'report', 'algebraic', 'language', 'december', 'perlis'], ['extraction', 'roots', 'digital', 'computers', 'december'], ['techniques', 'department', 'matrix', 'program', 'schemes', 'december'], ['engineering', 'programming', 'terminology', 'november'], ['square', 'root', 'approximations', 'november'], ['computers', 'procedures', 'november'], ['engineering', 'programming', 'terminology', 'october'], ['equivalence', 'transformation', 'program', 'schemes', 'october'], ['proposal', 'october'], ['engineering', 'programming', 'terminology', 'september']]\n"
     ]
    }
   ],
   "source": [
    "file = open (\"cacm.txt\",\"r\")\n",
    "globalWordList = list()\n",
    "\n",
    "for line in file:\n",
    "    wordlist = line.split()\n",
    "    globalWordList.append(wordlist)\n",
    "print(globalWordList[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 1845\n",
      "most common: [('data', 950), ('january', 934), ('program', 843), ('programming', 790), ('time', 783), ('language', 774), ('method', 722), ('systems', 707), ('problem', 524), ('paper', 515)]\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "for ii, document in enumerate(globalWordList):\n",
    "    for token in document :\n",
    "        word_counts[token] += 1\n",
    "\n",
    "tok2indx = {tok: indx for indx, tok in enumerate(word_counts.keys())}\n",
    "indx2tok = {indx: tok for tok,indx in tok2indx.items()}\n",
    "print('vocabulary size: {}'.format(len(word_counts)))\n",
    "print('most common: {}'.format(word_counts.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of wordpairs: 199260\n",
      "most common: [('language', 'programming', 159), ('programming', 'language', 159), ('time', 'sharing', 141), ('sharing', 'time', 141), ('programming', 'languages', 137), ('languages', 'programming', 137), ('information', 'retrieval', 116), ('retrieval', 'information', 116), ('language', 'language', 110), ('program', 'program', 106)]\n"
     ]
    }
   ],
   "source": [
    "back_window = 2\n",
    "front_window = 2\n",
    "wordpair_counts = Counter()\n",
    "for idocument , document  in enumerate(globalWordList):\n",
    "    tokens = [tok2indx[tok] for tok in document ]\n",
    "    for ii_word, word in enumerate(tokens):\n",
    "        ii_pair_min = max(0, ii_word - back_window)\n",
    "        ii_pair_max = min(len(document) - 1, ii_word + front_window)\n",
    "        ii_pairs = [\n",
    "            ii for ii in range(ii_pair_min, ii_pair_max + 1) \n",
    "            if ii != ii_word]\n",
    "        for ii_pair in ii_pairs:\n",
    "            wordpair = (tokens[ii_word], tokens[ii_pair])\n",
    "            wordpair_counts[wordpair] += 1    \n",
    "print('number of wordpairs: {}'.format(len(wordpair_counts)))\n",
    "most_common = [\n",
    "    (indx2tok[wp[0][0]], indx2tok[wp[0][1]], wp[1]) \n",
    "    for wp in wordpair_counts.most_common(10)]\n",
    "print('most common: {}'.format(most_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = []\n",
    "col_id = []\n",
    "dat_values = []\n",
    "ii = 0\n",
    "for (tok1, tok2), wp_count in wordpair_counts.items():   \n",
    "    row_id.append(tok1)\n",
    "    col_id.append(tok2)\n",
    "    dat_values.append(wp_count)\n",
    "wwcnt_mat = sparse.csr_matrix((dat_values, (row_id, col_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ww_sim(word, mat, topn):\n",
    "    \"\"\"Calculate topn most similar words to word\"\"\"\n",
    "    indx = tok2indx[word]\n",
    "    if isinstance(mat, sparse.csr_matrix):\n",
    "        v1 = mat.getrow(indx)\n",
    "    else:\n",
    "        v1 = mat[indx:indx+1, :]\n",
    "    sims = cosine_similarity(mat, v1).flatten()\n",
    "    sindxs = np.argsort(-sims)\n",
    "    sim_word_scores = [(indx2tok[sindx]) for sindx in sindxs[0:topn]]\n",
    "    return sim_word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['programming', 'nonprocedural', 'semantics', 'natural', 'language']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim('programming', wwcnt_mat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wordpairs = wwcnt_mat.sum()\n",
    "assert(sum(wordpair_counts.values())==num_wordpairs)\n",
    "\n",
    "# for creating sparce matrices\n",
    "row_id = []\n",
    "col_id = []\n",
    "\n",
    "pmi_dat_values = []    # pointwise mutual information\n",
    "\n",
    "\n",
    "# sum_over_rows[ii] = sum_over_words[ii] = wwcnt_mat.getcol(ii).sum()\n",
    "sum_over_words = np.array(wwcnt_mat.sum(axis=0)).flatten()\n",
    "# sum_over_cols[ii] = sum_over_pairs[ii] = wwcnt_mat.getrow(ii).sum()\n",
    "sum_over_pairs = np.array(wwcnt_mat.sum(axis=1)).flatten()\n",
    "\n",
    "for (tok_word, tok_pair), wp_count in wordpair_counts.items():\n",
    "    \n",
    "    nwc = wp_count\n",
    "    Pwc = (nwc + 0.25)/ (1 + num_wordpairs)\n",
    "    nw = sum_over_pairs[tok_word]\n",
    "    Pw = (nw + 0.5)/ (1 + num_wordpairs)\n",
    "    nc = sum_over_words[tok_pair]\n",
    "    Pc = (nc + 0.5)/ (1 + num_wordpairs)\n",
    "    \n",
    "    #  pmi = log {P(w,c) / [P(w) P(c)]} \n",
    "    pmi = np.log2(Pwc/(Pw*Pc))   \n",
    "    \n",
    "    row_id.append(tok_word)\n",
    "    col_id.append(tok_pair)\n",
    "    pmi_dat_values.append(pmi)\n",
    "            \n",
    "pmi_mat = sparse.csr_matrix((pmi_dat_values, (row_id, col_id)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['programming', 'languages', 'language', 'systems', 'programs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim('programming', pmi_mat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['january', 'december', 'august', 'april', 'october']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim('january', pmi_mat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
